{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d447da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import datetime\n",
    "import joblib\n",
    "from functools import partial\n",
    "\n",
    "# Import ML Packages\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753ddd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading finished!\n"
     ]
    }
   ],
   "source": [
    "file_list = glob(\"../data/input_1D/*.csv\")\n",
    "\n",
    "pm_df = [pd.read_csv(file, low_memory=False) for file in file_list]\n",
    "pm_df = pd.concat(pm_df, ignore_index=True)\n",
    "\n",
    "print(\"Data loading finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def62340",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab880c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(all_df, buffer_avg=True, target=\"047\", validation=False):\n",
    "    \n",
    "    if buffer_avg:\n",
    "        feature_list = ['aod_047', 'aod_055', 'aod_buffer_047', 'aod_buffer_055',  # 'avg_pm25',\n",
    "                        'day_cos', 'day_sin', 'daymet_dayl', 'daymet_lat', 'daymet_lon',\n",
    "                        'daymet_prcp', 'daymet_srad', 'daymet_tmax', 'daymet_tmin', 'daymet_vp',\n",
    "                        'dem', 'gridmet_th', 'gridmet_vs',  # 'knnidw_distance', 'knnidw_pm25', 'knnidw_pm25_val',\n",
    "                        'month_cos', 'month_sin', 'ndvi', 'wildfire_smoke',\n",
    "                        'year']\n",
    "\n",
    "    else:\n",
    "        feature_list = ['aod_047', 'aod_055',  # 'aod_buffer_047', 'aod_buffer_055',  # 'avg_pm25',\n",
    "                        'day_cos', 'day_sin', 'daymet_dayl', 'daymet_lat', 'daymet_lon',\n",
    "                        'daymet_prcp', 'daymet_srad', 'daymet_tmax', 'daymet_tmin', 'daymet_vp',\n",
    "                        'dem', 'gridmet_th', 'gridmet_vs',  # 'knnidw_distance', 'knnidw_pm25', 'knnidw_pm25_val',\n",
    "                        'month_cos', 'month_sin', 'ndvi', 'wildfire_smoke',\n",
    "                        'year']\n",
    "\n",
    "    all_df = all_df[feature_list]\n",
    "    # Filter out records have grount truth\n",
    "    all_df = all_df[all_df[f'aod_{target}'].notnull()]\n",
    "    if buffer_avg:\n",
    "        all_df = all_df[all_df[f'aod_buffer_{target}'].notnull()]\n",
    "        print(f\"Total Samples | Buffer: {buffer_avg}: {all_df.shape}\")\n",
    "\n",
    "    # Fill NaNs or RF cannot work\n",
    "    all_df = all_df.fillna(-1)\n",
    "\n",
    "    # Setting Hyperparameters. Please refer to the SI for more information\n",
    "    if buffer_avg:\n",
    "        xgb_params = dict(learning_rate=np.arange(0.05, 0.5, 0.05),\n",
    "                          eta=np.arange(0.1, 0.5, 0.1),\n",
    "                          n_estimators=np.arange(100, 1500, 100),\n",
    "                          gamma=np.arange(1, 10, 1),\n",
    "                          subsample=np.arange(0.1, 1.0, 0.01),\n",
    "                          max_depth=[int(i) for i in np.arange(3, 12, 1)],\n",
    "                          colsample_bytree=np.arange(0.1, 1.0, 0.2),\n",
    "                          )\n",
    "    else:\n",
    "        xgb_params = dict(learning_rate=np.arange(0.01, 0.3, 0.03),\n",
    "                          eta=np.arange(0.1, 0.5, 0.1),\n",
    "                          n_estimators=np.arange(100, 1500, 100),\n",
    "                          gamma=np.arange(1, 10, 1),\n",
    "                          subsample=np.arange(0.8, 1.0, 0.02),\n",
    "                          max_depth=[int(i) for i in np.arange(1, 12, 1)],\n",
    "                          colsample_bytree=np.arange(0.1, 1.0, 0.2),\n",
    "                          )\n",
    "    \n",
    "    num_fold = 1\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    for train_idx, test_idx in kfold.split(all_df):\n",
    "        \n",
    "        print(f\"Num Fold: {num_fold}\")\n",
    "        \n",
    "        val_df = all_df.iloc[test_idx]\n",
    "        train_df = all_df.iloc[train_idx]\n",
    "        \n",
    "\n",
    "        # inititalization\n",
    "        xgb_regressor = xgboost.XGBRegressor(booster='gbtree',\n",
    "                                             # objective='reg:squarederror',\n",
    "                                             verbosity=0,\n",
    "                                             tree_method='gpu_hist')\n",
    "\n",
    "        # find optimal parameters for random forest regressor using  RandomizedSearchCV.\n",
    "        # Set random_state=42 and be careful about scoring type\n",
    "        xgb_regressor_cv = RandomizedSearchCV(xgb_regressor, xgb_params, cv=5,\n",
    "                                              n_iter=50,\n",
    "                                              scoring='neg_root_mean_squared_error',\n",
    "                                              n_jobs=12)\n",
    "\n",
    "        if validation:\n",
    "            train_df, val_df = train_test_split(train_df, test_size=0.1)\n",
    "\n",
    "            X_train = train_df.drop(columns=['aod_047', 'aod_055'])\n",
    "            y_train = train_df[[f'aod_{target}']]\n",
    "\n",
    "            X_val = val_df.drop(columns=['aod_047', 'aod_055'])\n",
    "            y_val = val_df[[f'aod_{target}']]\n",
    "        else:\n",
    "            val_df = None\n",
    "            X_train = train_df.drop(columns=['aod_047', 'aod_055'])\n",
    "            y_train = train_df[[f'aod_{target}']]\n",
    "\n",
    "        xgb_regressor_cv.fit(X_train, y_train.values.ravel())\n",
    "        best_params = xgb_regressor_cv.best_params_\n",
    "        print(best_params)\n",
    "\n",
    "        # create best_rf_regressor sunig the parameters above and fit it to training data\n",
    "        best_xgb_regressor = xgb_regressor_cv.best_estimator_\n",
    "        best_xgb_regressor.fit(X_train, y_train.values.ravel())\n",
    "        # model evaluation for training set\n",
    "        train_r2_xgb = round(best_xgb_regressor.score(X_train, y_train), 2)\n",
    "        print('Training R2 score of XGBoost is {}'.format(train_r2_xgb))\n",
    "        y_train_predicted_xgb = best_xgb_regressor.predict(X_train)\n",
    "        rmse_train_xgb = (np.sqrt(mean_squared_error(y_train, y_train_predicted_xgb)))\n",
    "        print('RMSE on the training set for the XGBoost model is: {}'.format(rmse_train_xgb))\n",
    "        mbe_train_xgb = np.mean(y_train_predicted_xgb - y_train.values.squeeze())\n",
    "        print(\"MBE on training set is for the XGBoost model is: {}\".format(mbe_train_xgb))\n",
    "\n",
    "        if validation:\n",
    "            # model evaluation for test set\n",
    "            y_test_predicted_xgb = best_xgb_regressor.predict(X_val)\n",
    "            rmse_test_xgb = (np.sqrt(mean_squared_error(y_val, y_test_predicted_xgb)))\n",
    "            print(\"RMSE on testing set is for the XGBoost model is: {}\".format(rmse_test_xgb))\n",
    "\n",
    "            mbe_test_xgb = np.mean(y_test_predicted_xgb - y_val.values.squeeze())\n",
    "            print(\"MBE on testing set is for the XGBoost model is: {}\".format(mbe_test_xgb))\n",
    "        \n",
    "        num_fold += 1\n",
    "\n",
    "    print(\"================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c744e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Model w/o Buffer Average...\n",
      "Num Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8200000000000001, 'n_estimators': 700, 'max_depth': 11, 'learning_rate': 0.19, 'gamma': 3, 'eta': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.94\n",
      "RMSE on the training set for the XGBoost model is: 36.43885098130988\n",
      "MBE on training set is for the XGBoost model is: -0.006838233702145408\n",
      "RMSE on testing set is for the XGBoost model is: 82.54945891876815\n",
      "MBE on testing set is for the XGBoost model is: 0.7028795780456856\n",
      "Num Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9600000000000002, 'n_estimators': 1100, 'max_depth': 11, 'learning_rate': 0.22, 'gamma': 1, 'eta': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001}\n",
      "Training R2 score of XGBoost is 0.97\n",
      "RMSE on the training set for the XGBoost model is: 24.55542521116732\n",
      "MBE on training set is for the XGBoost model is: -0.00465296548366278\n",
      "RMSE on testing set is for the XGBoost model is: 80.91742591930247\n",
      "MBE on testing set is for the XGBoost model is: 0.4661441871866485\n",
      "Num Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'n_estimators': 600, 'max_depth': 11, 'learning_rate': 0.19, 'gamma': 1, 'eta': 0.1, 'colsample_bytree': 0.7000000000000001}\n",
      "Training R2 score of XGBoost is 0.92\n",
      "RMSE on the training set for the XGBoost model is: 41.357271871910406\n",
      "MBE on training set is for the XGBoost model is: -0.00228407204733947\n",
      "RMSE on testing set is for the XGBoost model is: 82.98095509536745\n",
      "MBE on testing set is for the XGBoost model is: 0.3254806427097767\n",
      "Num Fold: 4\n",
      "{'subsample': 0.9000000000000001, 'n_estimators': 1400, 'max_depth': 10, 'learning_rate': 0.19, 'gamma': 4, 'eta': 0.4, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.95\n",
      "RMSE on the training set for the XGBoost model is: 31.96631310039628\n",
      "MBE on training set is for the XGBoost model is: -0.008127053272803778\n",
      "RMSE on testing set is for the XGBoost model is: 81.37127323700919\n",
      "MBE on testing set is for the XGBoost model is: 0.957002674591931\n",
      "Num Fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9800000000000002, 'n_estimators': 1100, 'max_depth': 11, 'learning_rate': 0.06999999999999999, 'gamma': 8, 'eta': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.89\n",
      "RMSE on the training set for the XGBoost model is: 48.36963892907919\n",
      "MBE on training set is for the XGBoost model is: -0.006484482623156848\n",
      "RMSE on testing set is for the XGBoost model is: 80.60226761776337\n",
      "MBE on testing set is for the XGBoost model is: -0.026053608634408566\n",
      "Num Fold: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8400000000000001, 'n_estimators': 900, 'max_depth': 11, 'learning_rate': 0.06999999999999999, 'gamma': 9, 'eta': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.88\n",
      "RMSE on the training set for the XGBoost model is: 50.87487964089153\n",
      "MBE on training set is for the XGBoost model is: -0.01065743914026476\n",
      "RMSE on testing set is for the XGBoost model is: 81.8484879627173\n",
      "MBE on testing set is for the XGBoost model is: 0.24519954064187524\n",
      "Num Fold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9600000000000002, 'n_estimators': 1000, 'max_depth': 11, 'learning_rate': 0.09999999999999999, 'gamma': 9, 'eta': 0.1, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.91\n",
      "RMSE on the training set for the XGBoost model is: 42.69163065932037\n",
      "MBE on training set is for the XGBoost model is: -0.006675145970290243\n",
      "RMSE on testing set is for the XGBoost model is: 81.52046342577799\n",
      "MBE on testing set is for the XGBoost model is: 0.14079648147742896\n",
      "Num Fold: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8800000000000001, 'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.16, 'gamma': 2, 'eta': 0.4, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.9\n",
      "RMSE on the training set for the XGBoost model is: 47.00636527810286\n",
      "MBE on training set is for the XGBoost model is: -0.0063428540848732996\n",
      "RMSE on testing set is for the XGBoost model is: 83.88874966261724\n",
      "MBE on testing set is for the XGBoost model is: -0.2192263934691749\n",
      "Num Fold: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8400000000000001, 'n_estimators': 1000, 'max_depth': 11, 'learning_rate': 0.16, 'gamma': 1, 'eta': 0.30000000000000004, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.95\n",
      "RMSE on the training set for the XGBoost model is: 31.468517328675066\n",
      "MBE on training set is for the XGBoost model is: -0.00543976438425297\n",
      "RMSE on testing set is for the XGBoost model is: 82.61628303604512\n",
      "MBE on testing set is for the XGBoost model is: 0.11012735284023649\n",
      "Num Fold: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9000000000000001, 'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.22, 'gamma': 7, 'eta': 0.1, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.92\n",
      "RMSE on the training set for the XGBoost model is: 40.9857090794889\n",
      "MBE on training set is for the XGBoost model is: -0.014208427204259006\n",
      "RMSE on testing set is for the XGBoost model is: 82.48829569498876\n",
      "MBE on testing set is for the XGBoost model is: -0.050285440053400875\n",
      "================================================================================\n",
      "Num Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9200000000000002, 'n_estimators': 1300, 'max_depth': 11, 'learning_rate': 0.04, 'gamma': 5, 'eta': 0.1, 'colsample_bytree': 0.5000000000000001}\n",
      "Training R2 score of XGBoost is 0.85\n",
      "RMSE on the training set for the XGBoost model is: 41.22629816905262\n",
      "MBE on training set is for the XGBoost model is: -0.009717351406406352\n",
      "RMSE on testing set is for the XGBoost model is: 60.43983008678054\n",
      "MBE on testing set is for the XGBoost model is: 0.09101393856327651\n",
      "Num Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8600000000000001, 'n_estimators': 800, 'max_depth': 11, 'learning_rate': 0.16, 'gamma': 7, 'eta': 0.2, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.94\n",
      "RMSE on the training set for the XGBoost model is: 26.74124059211814\n",
      "MBE on training set is for the XGBoost model is: -0.00011739805579883692\n",
      "RMSE on testing set is for the XGBoost model is: 59.8481129662812\n",
      "MBE on testing set is for the XGBoost model is: 0.29040258334422087\n",
      "Num Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8400000000000001, 'n_estimators': 700, 'max_depth': 11, 'learning_rate': 0.19, 'gamma': 1, 'eta': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001}\n",
      "Training R2 score of XGBoost is 0.94\n",
      "RMSE on the training set for the XGBoost model is: 27.253038681353893\n",
      "MBE on training set is for the XGBoost model is: -0.008307569282939015\n",
      "RMSE on testing set is for the XGBoost model is: 59.47655226127396\n",
      "MBE on testing set is for the XGBoost model is: -0.02194302342376786\n",
      "Num Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8400000000000001, 'n_estimators': 1000, 'max_depth': 11, 'learning_rate': 0.09999999999999999, 'gamma': 8, 'eta': 0.1, 'colsample_bytree': 0.5000000000000001}\n",
      "Training R2 score of XGBoost is 0.91\n",
      "RMSE on the training set for the XGBoost model is: 32.2995380680289\n",
      "MBE on training set is for the XGBoost model is: -0.0034414681122831867\n",
      "RMSE on testing set is for the XGBoost model is: 59.95067327052892\n",
      "MBE on testing set is for the XGBoost model is: 0.19140121806281912\n",
      "Num Fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8600000000000001, 'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.13, 'gamma': 7, 'eta': 0.4, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.88\n",
      "RMSE on the training set for the XGBoost model is: 37.351053311010126\n",
      "MBE on training set is for the XGBoost model is: -0.013071872775581543\n",
      "RMSE on testing set is for the XGBoost model is: 61.301434958837106\n",
      "MBE on testing set is for the XGBoost model is: 0.20164535549902238\n",
      "Num Fold: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8400000000000001, 'n_estimators': 1400, 'max_depth': 11, 'learning_rate': 0.04, 'gamma': 4, 'eta': 0.2, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.87\n",
      "RMSE on the training set for the XGBoost model is: 38.62708162319665\n",
      "MBE on training set is for the XGBoost model is: -0.003811717407529024\n",
      "RMSE on testing set is for the XGBoost model is: 60.54099886403806\n",
      "MBE on testing set is for the XGBoost model is: 0.046434276742628275\n",
      "Num Fold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9400000000000002, 'n_estimators': 900, 'max_depth': 10, 'learning_rate': 0.25, 'gamma': 4, 'eta': 0.2, 'colsample_bytree': 0.5000000000000001}\n",
      "Training R2 score of XGBoost is 0.93\n",
      "RMSE on the training set for the XGBoost model is: 28.961854382501745\n",
      "MBE on training set is for the XGBoost model is: -0.005218178976377413\n",
      "RMSE on testing set is for the XGBoost model is: 63.105615111941056\n",
      "MBE on testing set is for the XGBoost model is: -0.17798231125616895\n",
      "Num Fold: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9600000000000002, 'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.16, 'gamma': 2, 'eta': 0.1, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.9\n",
      "RMSE on the training set for the XGBoost model is: 34.631931946288056\n",
      "MBE on training set is for the XGBoost model is: -0.0045113964518076035\n",
      "RMSE on testing set is for the XGBoost model is: 60.99886865534004\n",
      "MBE on testing set is for the XGBoost model is: -0.10839745904989904\n",
      "Num Fold: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9000000000000001, 'n_estimators': 700, 'max_depth': 11, 'learning_rate': 0.09999999999999999, 'gamma': 6, 'eta': 0.2, 'colsample_bytree': 0.9000000000000001}\n",
      "Training R2 score of XGBoost is 0.89\n",
      "RMSE on the training set for the XGBoost model is: 35.90272054665214\n",
      "MBE on training set is for the XGBoost model is: -0.005363469615559755\n",
      "RMSE on testing set is for the XGBoost model is: 61.073729165868514\n",
      "MBE on testing set is for the XGBoost model is: 0.14931762658867348\n",
      "Num Fold: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongying/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8200000000000001, 'n_estimators': 1400, 'max_depth': 10, 'learning_rate': 0.13, 'gamma': 9, 'eta': 0.4, 'colsample_bytree': 0.5000000000000001}\n",
      "Training R2 score of XGBoost is 0.92\n",
      "RMSE on the training set for the XGBoost model is: 31.112699664341584\n",
      "MBE on training set is for the XGBoost model is: 0.0019438448611496133\n",
      "RMSE on testing set is for the XGBoost model is: 59.56033344751647\n",
      "MBE on testing set is for the XGBoost model is: 0.15738527140541875\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Start Training Model with Buffer Average\n",
    "# print(\"Start Training Model with Buffer Average...\")\n",
    "# train_RF(all_df=pm_df, buffer_avg=True, target=\"047\", validation=True)\n",
    "# train_RF(all_df=pm_df, buffer_avg=True, target=\"055\", validation=True)\n",
    "\n",
    "# Start Training Model with Buffer Average\n",
    "print(\"Start Training Model w/o Buffer Average...\")\n",
    "train_RF(all_df=pm_df, buffer_avg=False, target=\"047\", validation=True)\n",
    "train_RF(all_df=pm_df, buffer_avg=False, target=\"055\", validation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c98717",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199b3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(all_df, buffer_avg=True, target=\"047\", validation=False):\n",
    "    \n",
    "    if buffer_avg:\n",
    "        feature_list = ['aod_047', 'aod_055', 'aod_buffer_047', 'aod_buffer_055',  # 'avg_pm25',\n",
    "                        'day_cos', 'day_sin', 'daymet_dayl', 'daymet_lat', 'daymet_lon',\n",
    "                        'daymet_prcp', 'daymet_srad', 'daymet_tmax', 'daymet_tmin', 'daymet_vp',\n",
    "                        'dem', 'gridmet_th', 'gridmet_vs',  # 'knnidw_distance', 'knnidw_pm25', 'knnidw_pm25_val',\n",
    "                        'month_cos', 'month_sin', 'ndvi', 'wildfire_smoke',\n",
    "                        'year']\n",
    "\n",
    "    else:\n",
    "        feature_list = ['aod_047', 'aod_055',  # 'aod_buffer_047', 'aod_buffer_055',  # 'avg_pm25',\n",
    "                        'day_cos', 'day_sin', 'daymet_dayl', 'daymet_lat', 'daymet_lon',\n",
    "                        'daymet_prcp', 'daymet_srad', 'daymet_tmax', 'daymet_tmin', 'daymet_vp',\n",
    "                        'dem', 'gridmet_th', 'gridmet_vs',  # 'knnidw_distance', 'knnidw_pm25', 'knnidw_pm25_val',\n",
    "                        'month_cos', 'month_sin', 'ndvi', 'wildfire_smoke',\n",
    "                        'year']\n",
    "\n",
    "    all_df = all_df[feature_list]\n",
    "    # Filter out records have grount truth\n",
    "    all_df = all_df[all_df[f'aod_{target}'].notnull()]\n",
    "    if buffer_avg:\n",
    "        all_df = all_df[all_df[f'aod_buffer_{target}'].notnull()]\n",
    "        print(f\"Total Samples | Buffer: {buffer_avg}: {all_df.shape}\")\n",
    "    else:\n",
    "        print(f\"Total Samples | Buffer: {buffer_avg}: {all_df.shape}\")\n",
    "\n",
    "    # Fill NaNs or RF cannot work\n",
    "    all_df = all_df.fillna(-1)\n",
    "\n",
    "    \n",
    "\n",
    "    rf_params = {'n_estimators': np.arange(30, 200, 10),\n",
    "                 'max_depth': np.arange(1, 15, 1),\n",
    "                 'min_samples_split': np.arange(2, 50, 1),\n",
    "                 'min_samples_leaf': np.arange(2, 50, 1),\n",
    "                 'max_features': ['sqrt', 'log2']}  # could also add 'criterion':['mse', 'mae'],\n",
    "    \n",
    "    num_fold = 1\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    for train_idx, test_idx in kfold.split(all_df):\n",
    "        \n",
    "        print(f\"Num Fold: {num_fold}\")\n",
    "        \n",
    "        val_df = all_df.iloc[test_idx]\n",
    "        train_df = all_df.iloc[train_idx]\n",
    "        \n",
    "\n",
    "        # inititalization\n",
    "        # rf_regressor = RandomForestRegressor(random_state=42)\n",
    "        rf_regressor = RandomForestRegressor()\n",
    "\n",
    "        # find optimal parameters for random forest regressor using  RandomizedSearchCV.\n",
    "        # Set random_state=42 and be careful about scoring type\n",
    "        xgb_regressor_cv = RandomizedSearchCV(rf_regressor, rf_params, cv=5,\n",
    "                                              n_iter=50,\n",
    "                                              scoring='neg_root_mean_squared_error',\n",
    "                                              n_jobs=16)\n",
    "\n",
    "        if validation:\n",
    "            train_df, val_df = train_test_split(train_df, test_size=0.1)\n",
    "\n",
    "            X_train = train_df.drop(columns=['aod_047', 'aod_055'])\n",
    "            y_train = train_df[[f'aod_{target}']]\n",
    "\n",
    "            X_val = val_df.drop(columns=['aod_047', 'aod_055'])\n",
    "            y_val = val_df[[f'aod_{target}']]\n",
    "        else:\n",
    "            val_df = None\n",
    "            X_train = train_df.drop(columns=['aod_047', 'aod_055'])\n",
    "            y_train = train_df[[f'aod_{target}']]\n",
    "\n",
    "        xgb_regressor_cv.fit(X_train, y_train.values.ravel())\n",
    "        best_params = xgb_regressor_cv.best_params_\n",
    "        print(best_params)\n",
    "\n",
    "        # create best_rf_regressor sunig the parameters above and fit it to training data\n",
    "        best_xgb_regressor = xgb_regressor_cv.best_estimator_\n",
    "        best_xgb_regressor.fit(X_train, y_train.values.ravel())\n",
    "        # model evaluation for training set\n",
    "        train_r2_xgb = round(best_xgb_regressor.score(X_train, y_train), 2)\n",
    "        print('Training R2 score of RF is {}'.format(train_r2_xgb))\n",
    "        y_train_predicted_xgb = best_xgb_regressor.predict(X_train)\n",
    "        rmse_train_xgb = (np.sqrt(mean_squared_error(y_train, y_train_predicted_xgb)))\n",
    "        print('RMSE on the training set for the RF model is: {}'.format(rmse_train_xgb))\n",
    "        mbe_train_xgb = np.mean(y_train_predicted_xgb - y_train.values.squeeze())\n",
    "        print(\"MBE on training set is for the RF model is: {}\".format(mbe_train_xgb))\n",
    "\n",
    "        if validation:\n",
    "            # model evaluation for test set\n",
    "            y_test_predicted_xgb = best_xgb_regressor.predict(X_val)\n",
    "            rmse_test_xgb = (np.sqrt(mean_squared_error(y_val, y_test_predicted_xgb)))\n",
    "            print(\"RMSE on testing set is for the RF model is: {}\".format(rmse_test_xgb))\n",
    "\n",
    "            mbe_test_xgb = np.mean(y_test_predicted_xgb - y_val.values.squeeze())\n",
    "            print(\"MBE on testing set is for the RF model is: {}\".format(mbe_test_xgb))\n",
    "        \n",
    "        num_fold += 1\n",
    "\n",
    "    print(\"================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d295a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Model with Buffer Average...\n",
      "Total Samples | Buffer: True: (1275632, 22)\n",
      "Num Fold: 1\n",
      "{'n_estimators': 170, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 30.360861978791387\n",
      "MBE on training set is for the RF model is: -0.007318139551022955\n",
      "RMSE on testing set is for the RF model is: 32.48922624657474\n",
      "MBE on testing set is for the RF model is: -0.0825099251621066\n",
      "Num Fold: 2\n",
      "{'n_estimators': 80, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 30.58117788928966\n",
      "MBE on training set is for the RF model is: -0.009090653213499117\n",
      "RMSE on testing set is for the RF model is: 31.627178899643855\n",
      "MBE on testing set is for the RF model is: -0.021065943605175344\n",
      "Num Fold: 3\n",
      "{'n_estimators': 110, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 30.023227314774587\n",
      "MBE on training set is for the RF model is: -0.0034968717290152344\n",
      "RMSE on testing set is for the RF model is: 30.695579723272495\n",
      "MBE on testing set is for the RF model is: -0.08276845168097009\n",
      "Num Fold: 4\n",
      "{'n_estimators': 120, 'min_samples_split': 17, 'min_samples_leaf': 12, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 30.30232164728154\n",
      "MBE on training set is for the RF model is: -0.008657846200584155\n",
      "RMSE on testing set is for the RF model is: 33.79946350206556\n",
      "MBE on testing set is for the RF model is: -0.027096809820377293\n",
      "Num Fold: 5\n",
      "{'n_estimators': 110, 'min_samples_split': 23, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 30.478470597198946\n",
      "MBE on training set is for the RF model is: -0.0024460705443624204\n",
      "RMSE on testing set is for the RF model is: 31.302041964640686\n",
      "MBE on testing set is for the RF model is: -0.1405132981558171\n",
      "Num Fold: 6\n",
      "{'n_estimators': 90, 'min_samples_split': 42, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 30.545176821332507\n",
      "MBE on training set is for the RF model is: 0.0019729874380905984\n",
      "RMSE on testing set is for the RF model is: 31.650235302823187\n",
      "MBE on testing set is for the RF model is: 0.05372766550102407\n",
      "Num Fold: 7\n",
      "{'n_estimators': 190, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 30.16648863128693\n",
      "MBE on training set is for the RF model is: -0.0013647780606298218\n",
      "RMSE on testing set is for the RF model is: 31.41169098332425\n",
      "MBE on testing set is for the RF model is: -0.011858654870417346\n",
      "Num Fold: 8\n",
      "{'n_estimators': 40, 'min_samples_split': 31, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 12}\n",
      "Training R2 score of RF is 0.95\n",
      "RMSE on the training set for the RF model is: 31.224536392646968\n",
      "MBE on training set is for the RF model is: -0.010552683722162781\n",
      "RMSE on testing set is for the RF model is: 31.783474348586562\n",
      "MBE on testing set is for the RF model is: -0.0444069764085523\n",
      "Num Fold: 9\n",
      "{'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 29.951153871521598\n",
      "MBE on training set is for the RF model is: -0.003220243090093488\n",
      "RMSE on testing set is for the RF model is: 31.098137818354616\n",
      "MBE on testing set is for the RF model is: -0.09238742804183801\n",
      "Num Fold: 10\n",
      "{'n_estimators': 140, 'min_samples_split': 36, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 30.738705483052374\n",
      "MBE on training set is for the RF model is: -0.007868517405861964\n",
      "RMSE on testing set is for the RF model is: 31.68368647263366\n",
      "MBE on testing set is for the RF model is: 0.22330348313884307\n",
      "================================================================================\n",
      "Total Samples | Buffer: True: (1263662, 22)\n",
      "Num Fold: 1\n",
      "{'n_estimators': 40, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 22.04592980547063\n",
      "MBE on training set is for the RF model is: -0.0006755113497351181\n",
      "RMSE on testing set is for the RF model is: 23.005678804074773\n",
      "MBE on testing set is for the RF model is: -0.11687085478901346\n",
      "Num Fold: 2\n",
      "{'n_estimators': 60, 'min_samples_split': 30, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 22.435873808267047\n",
      "MBE on training set is for the RF model is: -0.007582409404660045\n",
      "RMSE on testing set is for the RF model is: 23.880117682373736\n",
      "MBE on testing set is for the RF model is: -0.036872915716087064\n",
      "Num Fold: 3\n",
      "{'n_estimators': 90, 'min_samples_split': 33, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 22.597766822865104\n",
      "MBE on training set is for the RF model is: -0.0030721957375117463\n",
      "RMSE on testing set is for the RF model is: 23.925600661699185\n",
      "MBE on testing set is for the RF model is: -0.09380100673790678\n",
      "Num Fold: 4\n",
      "{'n_estimators': 160, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 21.809509032599983\n",
      "MBE on training set is for the RF model is: -0.004429892036069379\n",
      "RMSE on testing set is for the RF model is: 22.571543032299477\n",
      "MBE on testing set is for the RF model is: 0.04972774674311091\n",
      "Num Fold: 5\n",
      "{'n_estimators': 130, 'min_samples_split': 17, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 22.174966126798022\n",
      "MBE on training set is for the RF model is: -0.007469238496781593\n",
      "RMSE on testing set is for the RF model is: 23.14611303260241\n",
      "MBE on testing set is for the RF model is: 0.13326462337757303\n",
      "Num Fold: 6\n",
      "{'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 12}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 22.236068337952567\n",
      "MBE on training set is for the RF model is: -0.006740507041283021\n",
      "RMSE on testing set is for the RF model is: 22.69376370785112\n",
      "MBE on testing set is for the RF model is: -0.029817953618349453\n",
      "Num Fold: 7\n",
      "{'n_estimators': 80, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 21.69626976743095\n",
      "MBE on training set is for the RF model is: -0.006969877355159547\n",
      "RMSE on testing set is for the RF model is: 22.88464512329674\n",
      "MBE on testing set is for the RF model is: 0.03307324453154791\n",
      "Num Fold: 8\n",
      "{'n_estimators': 90, 'min_samples_split': 16, 'min_samples_leaf': 18, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.95\n",
      "RMSE on the training set for the RF model is: 22.808364645754363\n",
      "MBE on training set is for the RF model is: -0.0007550092119623272\n",
      "RMSE on testing set is for the RF model is: 23.14642549393463\n",
      "MBE on testing set is for the RF model is: -0.09232942191520525\n",
      "Num Fold: 9\n",
      "{'n_estimators': 40, 'min_samples_split': 29, 'min_samples_leaf': 14, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.96\n",
      "RMSE on the training set for the RF model is: 22.596687136058335\n",
      "MBE on training set is for the RF model is: -0.00427883922915598\n",
      "RMSE on testing set is for the RF model is: 23.043807900595116\n",
      "MBE on testing set is for the RF model is: 0.02569853703494128\n",
      "Num Fold: 10\n",
      "{'n_estimators': 130, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training set for the RF model is: 22.245747298061254\n",
      "MBE on training set is for the RF model is: -0.003723200249356273\n",
      "RMSE on testing set is for the RF model is: 22.87750866474507\n",
      "MBE on testing set is for the RF model is: 0.052472698039162984\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Start Training Model with Buffer Average\n",
    "print(\"Start Training Model with Buffer Average...\")\n",
    "train_RF(all_df=pm_df, buffer_avg=True, target=\"047\", validation=True)\n",
    "train_RF(all_df=pm_df, buffer_avg=True, target=\"055\", validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79fe6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Model with Buffer Average...\n",
      "Start Training Model w/o Buffer Average...\n",
      "Total Samples | Buffer: False: (1275632, 20)\n",
      "Num Fold: 1\n",
      "{'n_estimators': 100, 'min_samples_split': 22, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.54\n",
      "RMSE on the training set for the RF model is: 98.64197380543906\n",
      "MBE on training set is for the RF model is: 0.007558329525689623\n",
      "RMSE on testing set is for the RF model is: 104.02996707387894\n",
      "MBE on testing set is for the RF model is: 0.30160752654664413\n",
      "Num Fold: 2\n",
      "{'n_estimators': 60, 'min_samples_split': 41, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.56\n",
      "RMSE on the training set for the RF model is: 97.03707708524625\n",
      "MBE on training set is for the RF model is: 0.006239897757268297\n",
      "RMSE on testing set is for the RF model is: 99.948024047647\n",
      "MBE on testing set is for the RF model is: -0.060663130540534876\n",
      "Num Fold: 3\n",
      "{'n_estimators': 120, 'min_samples_split': 10, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.55\n",
      "RMSE on the training set for the RF model is: 97.36329659852211\n",
      "MBE on training set is for the RF model is: -0.021127931988740325\n",
      "RMSE on testing set is for the RF model is: 100.22246240028142\n",
      "MBE on testing set is for the RF model is: 0.08076129934864676\n",
      "Num Fold: 4\n",
      "{'n_estimators': 120, 'min_samples_split': 19, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.55\n",
      "RMSE on the training set for the RF model is: 97.34271145587913\n",
      "MBE on training set is for the RF model is: -0.009501164275885212\n",
      "RMSE on testing set is for the RF model is: 101.80271318291615\n",
      "MBE on testing set is for the RF model is: -0.04244314853038313\n",
      "Num Fold: 5\n",
      "{'n_estimators': 60, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.58\n",
      "RMSE on the training set for the RF model is: 94.2075633531814\n",
      "MBE on training set is for the RF model is: -0.009659824170899394\n",
      "RMSE on testing set is for the RF model is: 99.9662755486373\n",
      "MBE on testing set is for the RF model is: -0.7286615090578703\n",
      "Num Fold: 6\n",
      "{'n_estimators': 80, 'min_samples_split': 26, 'min_samples_leaf': 18, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.55\n",
      "RMSE on the training set for the RF model is: 98.02638004851995\n",
      "MBE on training set is for the RF model is: -0.04858664460241979\n",
      "RMSE on testing set is for the RF model is: 101.64874194892909\n",
      "MBE on testing set is for the RF model is: 0.4085036759877252\n",
      "Num Fold: 7\n",
      "{'n_estimators': 40, 'min_samples_split': 3, 'min_samples_leaf': 14, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.56\n",
      "RMSE on the training set for the RF model is: 97.08894851534846\n",
      "MBE on training set is for the RF model is: 0.006809137271269717\n",
      "RMSE on testing set is for the RF model is: 100.87329997436089\n",
      "MBE on testing set is for the RF model is: 0.00827035764136604\n",
      "Num Fold: 8\n",
      "{'n_estimators': 170, 'min_samples_split': 39, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.56\n",
      "RMSE on the training set for the RF model is: 96.91273665663446\n",
      "MBE on training set is for the RF model is: -0.004416517891131391\n",
      "RMSE on testing set is for the RF model is: 102.23275268524259\n",
      "MBE on testing set is for the RF model is: 0.16776261241893323\n",
      "Num Fold: 9\n",
      "{'n_estimators': 150, 'min_samples_split': 13, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.54\n",
      "RMSE on the training set for the RF model is: 99.30120869417262\n",
      "MBE on training set is for the RF model is: -0.02669077102066103\n",
      "RMSE on testing set is for the RF model is: 102.27155145837452\n",
      "MBE on testing set is for the RF model is: 0.2043794637322916\n",
      "Num Fold: 10\n",
      "{'n_estimators': 70, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.56\n",
      "RMSE on the training set for the RF model is: 96.95297923133047\n",
      "MBE on training set is for the RF model is: -0.01960560180777156\n",
      "RMSE on testing set is for the RF model is: 102.25084971745429\n",
      "MBE on testing set is for the RF model is: -0.4929219860543141\n",
      "================================================================================\n",
      "Total Samples | Buffer: False: (1263662, 20)\n",
      "Num Fold: 1\n",
      "{'n_estimators': 140, 'min_samples_split': 33, 'min_samples_leaf': 18, 'max_features': 'log2', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.53\n",
      "RMSE on the training set for the RF model is: 73.48835002600435\n",
      "MBE on training set is for the RF model is: -0.015500460247214926\n",
      "RMSE on testing set is for the RF model is: 76.02548176019066\n",
      "MBE on testing set is for the RF model is: -0.08614703171929979\n",
      "Num Fold: 2\n",
      "{'n_estimators': 180, 'min_samples_split': 3, 'min_samples_leaf': 14, 'max_features': 'sqrt', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.56\n",
      "RMSE on the training set for the RF model is: 71.24634690493191\n",
      "MBE on training set is for the RF model is: -0.006725133366092533\n",
      "RMSE on testing set is for the RF model is: 75.20243982288987\n",
      "MBE on testing set is for the RF model is: 0.09931924398044137\n",
      "Num Fold: 3\n",
      "{'n_estimators': 130, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.57\n",
      "RMSE on the training set for the RF model is: 70.47794128151538\n",
      "MBE on training set is for the RF model is: -0.03603483770126924\n",
      "RMSE on testing set is for the RF model is: 73.8906713443673\n",
      "MBE on testing set is for the RF model is: 0.011880265211133648\n",
      "Num Fold: 4\n",
      "{'n_estimators': 140, 'min_samples_split': 27, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.56\n",
      "RMSE on the training set for the RF model is: 71.25634376823186\n",
      "MBE on training set is for the RF model is: -0.014866716777926975\n",
      "RMSE on testing set is for the RF model is: 74.51064773157002\n",
      "MBE on testing set is for the RF model is: -0.6636731313070973\n",
      "Num Fold: 5\n",
      "{'n_estimators': 140, 'min_samples_split': 30, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.57\n",
      "RMSE on the training set for the RF model is: 70.37625764404369\n",
      "MBE on training set is for the RF model is: -0.00433300264930275\n",
      "RMSE on testing set is for the RF model is: 74.14462796127643\n",
      "MBE on testing set is for the RF model is: -0.2989055382480116\n",
      "Num Fold: 6\n",
      "{'n_estimators': 150, 'min_samples_split': 41, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.55\n",
      "RMSE on the training set for the RF model is: 71.68587754653656\n",
      "MBE on training set is for the RF model is: 0.003945094427548925\n",
      "RMSE on testing set is for the RF model is: 74.5510810270654\n",
      "MBE on testing set is for the RF model is: -0.2598024000186836\n",
      "Num Fold: 7\n",
      "{'n_estimators': 80, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.56\n",
      "RMSE on the training set for the RF model is: 71.27593334537106\n",
      "MBE on training set is for the RF model is: -0.02153996319521281\n",
      "RMSE on testing set is for the RF model is: 75.8750759159155\n",
      "MBE on testing set is for the RF model is: -0.11619703205293595\n",
      "Num Fold: 8\n",
      "{'n_estimators': 170, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 12}\n",
      "Training R2 score of RF is 0.53\n",
      "RMSE on the training set for the RF model is: 73.42325392993438\n",
      "MBE on training set is for the RF model is: -0.02369602290181261\n",
      "RMSE on testing set is for the RF model is: 75.36277743094648\n",
      "MBE on testing set is for the RF model is: 0.22831998512944532\n",
      "Num Fold: 9\n",
      "{'n_estimators': 190, 'min_samples_split': 15, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'max_depth': 13}\n",
      "Training R2 score of RF is 0.54\n",
      "RMSE on the training set for the RF model is: 72.33425179979385\n",
      "MBE on training set is for the RF model is: -0.01648004199267818\n",
      "RMSE on testing set is for the RF model is: 76.86597809193218\n",
      "MBE on testing set is for the RF model is: -0.40144659873784244\n",
      "Num Fold: 10\n",
      "{'n_estimators': 30, 'min_samples_split': 31, 'min_samples_leaf': 8, 'max_features': 'log2', 'max_depth': 14}\n",
      "Training R2 score of RF is 0.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training set for the RF model is: 70.83957046814007\n",
      "MBE on training set is for the RF model is: -0.007291361835540957\n",
      "RMSE on testing set is for the RF model is: 74.89681763942345\n",
      "MBE on testing set is for the RF model is: -0.1351011943226997\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Start Training Model with Buffer Average\n",
    "print(\"Start Training Model with Buffer Average...\")\n",
    "# train_RF(all_df=pm_df, buffer_avg=True, target=\"047\", validation=True)\n",
    "# train_RF(all_df=pm_df, buffer_avg=True, target=\"055\", validation=True)\n",
    "\n",
    "# Start Training Model with Buffer Average\n",
    "print(\"Start Training Model w/o Buffer Average...\")\n",
    "train_RF(all_df=pm_df, buffer_avg=False, target=\"047\", validation=True)\n",
    "train_RF(all_df=pm_df, buffer_avg=False, target=\"055\", validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e592f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
